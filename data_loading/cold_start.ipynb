{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Ratio of users to consider in warm start setting\n",
    "include_unknown = False\n",
    "warm_start_ratio = 0.75\n",
    "\n",
    "ratings = pd.read_csv(f'mindreader/ratings-mr100k.csv')\n",
    "if not include_unknown:\n",
    "    ratings = ratings[ratings.sentiment != 0]\n",
    "\n",
    "# Compute ratings per entity\n",
    "# In the future, this could be used for popularity sampling of negative samples\n",
    "entity_ratings = ratings[['uri', 'userId']].groupby('uri').count()\n",
    "entity_ratings.columns = ['num_ratings']\n",
    "\n",
    "# Filter users with less than two positive movie samples\n",
    "tmp = ratings[ratings.sentiment == 1 & ratings.isItem][['uri', 'userId']].groupby('userId').count()\n",
    "tmp.columns = ['pos_ratings']\n",
    "\n",
    "ratings = ratings[ratings.userId.isin(tmp[tmp.pos_ratings >= 2].index)]\n",
    "\n",
    "# Partition into warm and cold start users\n",
    "users = ratings['userId'].unique()\n",
    "random.shuffle(users)\n",
    "\n",
    "num_warm_start = int(len(users) * warm_start_ratio)\n",
    "warm_start_users = set(users[:num_warm_start])\n",
    "cold_start_users = set(users[num_warm_start:])\n",
    "\n",
    "assert warm_start_users.isdisjoint(cold_start_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sample_positive(from_ratings):\n",
    "    return random.choice(from_ratings[from_ratings.sentiment == 1 & from_ratings.isItem].entityIdx.unique())\n",
    "\n",
    "def sample_unseen_items(user_id, n_items=100):\n",
    "    item_ratings = ratings[ratings.isItem]\n",
    "    \n",
    "    seen_items = set(item_ratings[item_ratings.userId == user_id].entityIdx.unique())\n",
    "    unseen_items = list(set(item_ratings.entityIdx.unique()).difference(seen_items))\n",
    "   \n",
    "    random.shuffle(unseen_items)\n",
    "    \n",
    "    return unseen_items[:n_items]\n",
    "\n",
    "def get_ratings_dict(from_ratings):\n",
    "    return {row.entityIdx: row.sentiment for _, row in from_ratings.iterrows()}\n",
    "\n",
    "def get_validation_dict(user_id, left_out):\n",
    "    return {\n",
    "        'positive': left_out,\n",
    "        'negative': sample_unseen_items(user_id)\n",
    "    }\n",
    "\n",
    "# Map users and entities to indices\n",
    "user_idx = {k: v for v, k in enumerate(users)}\n",
    "entity_idx = {k: v for v, k in enumerate(ratings['uri'].unique())}\n",
    "\n",
    "ratings['entityIdx'] = ratings.uri.transform(entity_idx.get)\n",
    "\n",
    "# Generate training/validation data from warm start users\n",
    "training_data = dict()\n",
    "\n",
    "for user in warm_start_users:\n",
    "    u_ratings = ratings[ratings.userId == user]\n",
    "    \n",
    "    val_sample = sample_positive(u_ratings)\n",
    "    \n",
    "    training_dict = get_ratings_dict(u_ratings[u_ratings.entityIdx != val_sample])\n",
    "    validation_dict = get_validation_dict(user, val_sample)\n",
    "    \n",
    "    # Assert validation sample not in training\n",
    "    assert val_sample not in training_dict.keys()\n",
    "    \n",
    "    # Assert positive sample not in negative samples\n",
    "    assert val_sample not in validation_dict['negative']\n",
    "    \n",
    "    # Assert negative samples not in training\n",
    "    assert not set(validation_dict['negative']).intersection(training_dict.keys())\n",
    "\n",
    "    training_data[user_idx[user]] = {\n",
    "        'training': training_dict,\n",
    "        'validation': validation_dict\n",
    "    }\n",
    "    \n",
    "# Generate testing data from cold start users\n",
    "testing_data = dict()\n",
    "\n",
    "for user in cold_start_users:\n",
    "    u_ratings = ratings[ratings.userId == user]\n",
    "    \n",
    "    # Before exhaustive LOO, get validation sample\n",
    "    val_sample = sample_positive(u_ratings)\n",
    "    validation_dict = get_validation_dict(user, val_sample)\n",
    "    \n",
    "    # For convenience, leave out the validation sample from the user's ratings\n",
    "    u_ratings = u_ratings[u_ratings.entityIdx != val_sample]\n",
    "    \n",
    "    # Find all the user's positive item ratings\n",
    "    u_pos = u_ratings[u_ratings.isItem & u_ratings.sentiment == 1]\n",
    "    assert len(u_pos)\n",
    "    \n",
    "    # For each positive item, create an answer set with that item left out\n",
    "    sets = []\n",
    "    for idx, pos in u_pos.iterrows():\n",
    "        answer_dict = get_ratings_dict(u_ratings[u_ratings.entityIdx != pos.entityIdx])\n",
    "        pos_neg_dict = get_validation_dict(user, pos.entityIdx)\n",
    "        \n",
    "        # Skip if user cannot provide any answers\n",
    "        if not answer_dict:\n",
    "            continue\n",
    "        \n",
    "        # Assert that the positive item is not in the negative samples\n",
    "        assert pos.entityIdx not in pos_neg_dict['negative']\n",
    "        \n",
    "        # Assert that user cannot answer about the positive item\n",
    "        assert pos.entityIdx not in answer_dict\n",
    "        \n",
    "        sets.append({**pos_neg_dict, 'answers': answer_dict})\n",
    "    \n",
    "    # Check if user has any valid answer sets\n",
    "    if not sets:\n",
    "        continue\n",
    "    \n",
    "    testing_data[user_idx[user]] = {\n",
    "        'sets': sets,\n",
    "        'validation': validation_dict\n",
    "    }\n",
    "    \n",
    "    \n",
    "print(f'Created {len(training_data)} training entries and {len(testing_data)} testing entries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)\n",
    "\n",
    "with open('data/training.json', 'w') as fp:\n",
    "    json.dump(training_data, fp, cls=NpEncoder)\n",
    "    \n",
    "with open('data/testing.json', 'w') as fp:\n",
    "    json.dump(testing_data, fp, cls=NpEncoder)\n",
    "\n",
    "with open('data/meta.json', 'w') as fp:\n",
    "    json.dump({\n",
    "        'uri_idx': entity_idx,\n",
    "        'idx_item': {row.entityIdx: row.isItem for idx, row in ratings.iterrows()}\n",
    "    }, fp, cls=NpEncoder)\n",
    "\n",
    "print('Dumped data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}